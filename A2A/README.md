# ğŸ¤– Agent to Agent (A2A) - VideoSDK Multi-Agent Framework

The Agent to Agent (A2A) protocol enables seamless collaboration between specialized AI agents, allowing them to communicate, share knowledge, and coordinate responses based on their unique capabilities and domain expertise.

![A2A Architecture](https://cdn.videosdk.live/website-resources/docs-resources/a2a_diagram.png)

## ğŸŒŸ How It Works

1. **Agent Registration**: Agents register with capabilities and domain expertise
2. **Client Query**: User sends query to main agent
3. **Agent Discovery**: Main agent finds relevant specialists
4. **Query Forwarding**: Forwards specialized queries to appropriate agents
5. **Response Chain**: Specialists process and respond back
6. **Client Response**: Main agent delivers final response to user

### Example Scenario

```
Client â†’ "I want to know about personal loan rates"
   â†“
Customer Service Agent â†’ Discovers Loan Specialist Agent
   â†“
Customer Service Agent â†’ Forwards query to specialist
   â†“
Loan Specialist â†’ Processes with domain expertise
   â†“
Customer Service Agent â†’ Relays response to client
```

## ğŸ—ï¸ Quick Start

### Prerequisites
- Python 3.12 or higher
- VideoSDK authentication token
- Google Gemini API key
- OpenAI API key (for specialist agents)
- VideoSDK meeting ID

### Installation & Setup

1. **Navigate to A2A directory**:
```bash
cd agents-quickstart/A2A
```

2. **Install dependencies**:
```bash
pip install videosdk-agents
```

3. **Set environment variables**:
```bash
export VIDEOSDK_AUTH_TOKEN="your_videosdk_token"
export GOOGLE_API_KEY="your_gemini_api_key"
export OPENAI_API_KEY="your_openai_api_key"
```

4. **Update meeting ID** in `main.py`:
```python
room_id="YOUR_MEETING_ID"  # Replace with your meeting ID
```

5. **Run the system**:
```bash
python main.py
```

## ğŸ“ Project Structure

```
A2A/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ customer_agent.py     # Voice-enabled customer service agent
â”‚   â”œâ”€â”€ loan_agent.py         # Text-based loan specialist
â”‚   â””â”€â”€ README.md             # Implementation guide
â”œâ”€â”€ session_manager.py        # Session and pipeline management
â”œâ”€â”€ main.py                   # System entry point
â””â”€â”€ README.md                 # This file
```

## ğŸ’¬ Usage Example

1. **User**: *"Hi, I want to know about personal loan rates"*
2. **Customer Agent**: *"Let me get that information from our loan specialist..."*
3. **System**: Routes to Loan Agent â†’ processes â†’ returns response
4. **Customer Agent**: *"Personal loans are available starting at 8.5% APR..."*

## âœ¨ Key Features

- **Multi-Modal Communication**: Audio agents for users, text agents for processing
- **Domain Specialization**: Customer service, loans, and easily extensible to new domains
- **Intelligent Routing**: Automatic query detection and specialist forwarding
- **Real-Time Collaboration**: Seamless agent-to-agent communication

## ğŸ”§ Agent Configuration

### Customer Service Agent
- **RealTimePipeline** with Gemini Realtime model for low-latency voice interaction
- **Audio-enabled** with voice "Leda" for real-time conversation
- **Joins VideoSDK meeting** for user communication
- **Routes queries** to appropriate specialists

### Loan Specialist Agent
- **CascadingPipeline** with OpenAI LLM for efficient text processing
- **Text-based processing** for specialist responses
- **Background operation** (no meeting join required)
- **Domain expertise** in loan products and rates

## ğŸ”§ Pipeline Architecture

The system uses a **hybrid pipeline approach** for optimal performance:

### RealTimePipeline (Customer Agent)
- **Model**: Gemini Realtime (`gemini-2.0-flash-live-001`)
- **Voice**: "Leda" with audio response modality
- **Purpose**: Low-latency voice interaction with users
- **Benefits**: Natural conversation flow, real-time audio processing

### CascadingPipeline (Specialist Agent)
- **Model**: OpenAI LLM 
- **Processing**: Text-only for efficient specialist responses
- **Purpose**: Background processing of domain-specific queries
- **Benefits**: Cost-effective, optimized for text-based reasoning

This architecture ensures **fast user interaction** while maintaining **efficient specialist processing** in the background.

### ğŸ”§ Pipeline Flexibility

The VideoSDK AI Agents framework provides **flexible pipeline configurations**. You can run a full **RealTimePipeline** or **CascadingPipeline** for both modalities, or create a **hybrid setup** that combines the two. This allows you to tailor the use of STT, TTS, and LLM to suit your specific use case, whether for low-latency interactions, complex processing flows, or a mix of both.

**Configuration Examples** (available in `session_manager.py`):
- **Hybrid Setup** (Current): RealTimePipeline + CascadingPipeline
- **Full RealTime**: Both agents using RealTimePipeline
- **Full Cascading**: Both agents using CascadingPipeline  
- **Custom Mix**: Any combination based on your requirements

## ğŸŒŸ Benefits

- **Seamless Experience**: Single conversation with access to multiple specialists
- **Real-time Responses**: No waiting for transfers or callbacks
- **Expert Knowledge**: Domain-specific expertise delivered naturally
- **Cost Effective**: Reduce need for multiple human specialists

## ğŸ“š Learn More

- **[A2A Overview](https://docs.videosdk.live/ai_agents/a2a/overview)** - Core concepts and components
- **[A2A Implementation](https://docs.videosdk.live/ai_agents/a2a/implementation)** - Complete implementation guide
- **[Agent Architecture Guide](./agents/README.md)** - Detailed code examples
- **[VideoSDK AI Agents](https://docs.videosdk.live/ai_agents/introduction)** - Framework documentation

---

**Made with â¤ï¸ by the VideoSDK Team** | [Join our Discord](https://discord.com/invite/f2WsNDN9S5) 
